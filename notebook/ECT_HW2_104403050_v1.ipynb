{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_graphviz, DecisionTreeClassifier as DT\n",
    "from sklearn import metrics\n",
    "import graphviz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the dataset\n",
    "data = pd.read_csv('glass.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING\n",
    "\n",
    "#select an output class and feature classes\n",
    "x_ = data.iloc[:,0:9]\n",
    "y_ = data['Type']\n",
    "\n",
    "#label encoding(unnecessary)\n",
    "#from sklearn import preprocessing\n",
    "#lblecd = preprocessing.LabelEncoder()\n",
    "#y = lblecd.fit_transform(y_)\n",
    "\n",
    "#form the feature array(unnecessary)\n",
    "#x = x_.values\n",
    "\n",
    "#split into train/test set w/ the proportion of 141(66%):73(34%)\n",
    "#configure the shuffle = False, the training set would be as same as Weka\n",
    "train_x , test_x, train_lbl , test_lbl = train_test_split(x_, y_, test_size = 0.34, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=4, min_impurity_decrease=0.0,\n",
       "            min_impurity_split=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MODELING\n",
    "clf = DT(criterion = 'entropy', \n",
    "        max_depth = 3,\n",
    "        max_leaf_nodes = 4,)\n",
    "clf.fit(train_x, train_lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc(training set): 0.6524822695035462\n",
      "acc(testing set): 0.6164383561643836\n"
     ]
    }
   ],
   "source": [
    "#PREDICTING&TESTING\n",
    "pred1 = clf.predict(train_x)\n",
    "pred2 = clf.predict(test_x)\n",
    "\n",
    "print('acc(training set): ' + str(metrics.accuracy_score(train_lbl, pred1)))\n",
    "print('acc(testing set): ' + str(metrics.accuracy_score(test_lbl, pred2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  1  0  0  0  0  0]\n",
      " [10 17  0  0  0  0  1]\n",
      " [ 3  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  5  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  3]\n",
      " [ 0  2  0  0  0  0  7]]\n"
     ]
    }
   ],
   "source": [
    "a = clf.classes_ \n",
    "new = np.append(a, 'None')\n",
    "b[3], b[4], b[5] ,b[6] = 'None', a[3], a[5], a[4]\n",
    "\n",
    "#check out the confusion matrix, and reorder the attribute according to weka\n",
    "print(metrics.confusion_matrix(test_lbl, pred2, labels = b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZING\n",
    "\n",
    "def visualize_dt(clf_, name):\n",
    "    dot_data = tree.export_graphviz(clf_, out_file = None)\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    graph.render(str(name))\n",
    "    \n",
    "def acc_dt(clf_):\n",
    "    clf_.fit(train_x, train_lbl)\n",
    "    prediction = clf_.predict(test_x)\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(test_lbl, prediction)))\n",
    "    \n",
    "# Origianl DT\n",
    "visualize_dt(clf, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6301369863013698\n",
      "Accuracy: 0.6575342465753424\n",
      "Accuracy: 0.684931506849315\n"
     ]
    }
   ],
   "source": [
    "#IMPROVEMENT\n",
    "\n",
    "# I. Increase the max_leaf_nodes => 1.pdf\n",
    "clf_mln = DT(criterion = 'entropy', \n",
    "        max_depth = 3,\n",
    "        max_leaf_nodes = 10)\n",
    "\n",
    "acc_dt(clf_mln)\n",
    "visualize_dt(clf_mln, 1)\n",
    "\n",
    "# II. Increase max_depth => 2.pdf\n",
    "clf_md = DT(criterion = 'entropy', \n",
    "        max_depth = 6,\n",
    "        max_leaf_nodes = 10)\n",
    "\n",
    "acc_dt(clf_md)\n",
    "visualize_dt(clf_md, 2)\n",
    "\n",
    "# III. Increase min_samples_leaf => 3.pdf\n",
    "clf_msl = DT(criterion = 'entropy', \n",
    "        max_depth = 6,\n",
    "        max_leaf_nodes = 10,\n",
    "        min_samples_leaf = 5)\n",
    "\n",
    "acc_dt(clf_msl)\n",
    "visualize_dt(clf_msl, 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
